{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "<p style=\"text-align: center;font-size: 40pt\">ROS visualizer (Rviz)</p>\n",
    "<p style=\"text-align: center;font-size: 20pt\">3D visualization tool for ROS</p>\n",
    "<img src=\"images/rviz_snap_2.png\" width=\"100%\" alt=\"Retrieved from ros.org\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Fortunately, not everything is done through a terminal in ROS.\n",
    "[_Rviz_](http://wiki.ros.org/rviz) is a 3D visualization tool for ROS which allows us to inspect data flowing through ROS topics.\n",
    "It is especially well suited for displaying 3D data, such as point clouds, mesh models of robots, trajectories or markers.\n",
    "It also allows us to display streams of camera images.\n",
    "\n",
    "In this lesson, we will have a look on basic controls and settings which are necessary to correctly display point clouds, images and markers.\n",
    "For all other types of data, we will refer you to a [list of available displays](http://wiki.ros.org/rviz/DisplayTypes).\n",
    "Good news is that using them always follows the same pattern, so it is easy to learn using a new one.\n",
    "To put you in the mood, you can start by viewing this video:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from IPython.display import YouTubeVideo\n",
    "YouTubeVideo('i--Sd4xH9ZE', width=720, height=480)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Prerequisites\n",
    "\n",
    "The Rviz itself is already installed in your virtual machine as a component of ROS.\n",
    "Given that you have a `roscore` running in some terminal, you can enter `rviz` (same effect as `rosrun rviz rviz`) in another terminal and run it.\n",
    "You will see a default layout and no data displayed.\n",
    "\n",
    "To be able to play with Rviz displays, we need some data in ROS topics in the first place.\n",
    "On a real robot, those would be available after turning it on.\n",
    "On a PC, there is just a roscore running, so not much fun.\n",
    "To cope with that situation, we will use a topic-data-save-and-replay capability of ROS.\n",
    "This capability is named `rosbag` and will be properly introduced in the [next lesson](2.3-lesson-ros-rosbag.ipynb).\n",
    "But for now, simply proceed like this:\n",
    "\n",
    "1. Download the data file (a _rosbag_) from [this link](http://norlab.s3.valeria.science/percep3d/husky_short_demo.zip?AWSAccessKeyId=XMBLP3A0338XN5LASKV2&Expires=2286820630&Signature=Rjnfu1aENlutNl3m5hXB%2BReq6hE%3D) (around 260 MB) and uncompress it into the `~/percep3d_data` folder in your home folder. Or in command line:\n",
    "```bash\n",
    "$ cd ~/percep3d_data/\n",
    "$ wget -O husky_short_demo.zip \"http://norlab.s3.valeria.science/percep3d/husky_short_demo.zip?AWSAccessKeyId=XMBLP3A0338XN5LASKV2&Expires=2286820630&Signature=Rjnfu1aENlutNl3m5hXB%2BReq6hE%3D\"\n",
    "$ unzip husky_short_demo.zip\n",
    "$ rm bag.zip\n",
    "```\n",
    "<br>\n",
    "1. Run your `roscore` as usual (or keep running the one that you already have) and close Rviz if you still have one running.\n",
    "1. Open a new terminal and run these two commands:\n",
    "```\n",
    "$ rosparam set use_sim_time true\n",
    "$ rosbag play --clock -l ~/percep3d_data/husky_short_demo.bag\n",
    "```\n",
    "   <br>\n",
    "   Dealing with time is an entire topic outside the scope of this module.\n",
    "   To make is simple, let's just say that a clock was recorded in the bag at the time of the deployment.\n",
    "   The parameter `use_sim_time` tells ROS to **not** use the clock of your computer.\n",
    "   The flag `--clock` will produce a simulated clock from what was recorded in the bag.\n",
    "   Finally, the flag `-l` will keep playing the bagfile in a loop until terminated by pressing `CTRL+C`. \n",
    "   Keep it running for now.\n",
    "   \n",
    "1. Re-launch the Rviz from a terminal of your choice:\n",
    "\n",
    "```\n",
    "$ rviz\n",
    "```\n",
    "\n",
    "The bagfile which is playing in loop is a snippet from a DARPA competition deployment with our Husky robot.\n",
    "It is approximately half a minute long and contains all relevant sensor data that we used during the competition.\n",
    "In this lesson, we will use point clouds and images from this bagfile to see how they look in Rviz.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using Rviz\n",
    "\n",
    "## Rviz documentation online\n",
    "\n",
    "Start by looking at this [site](http://wiki.ros.org/rviz/UserGuide).\n",
    "It is a user guide for Rviz, just the screenshots are slightly outdated.\n",
    "You can use this site anytime as a reference on how different panels and controls in Rviz work.\n",
    "Just note that sections 1-3 have been already covered by what we have already done here, since you have one Rviz running at the moment.\n",
    "The interesting content begins with section 4, where _Displays_ are introduced.\n",
    "Read this section and try to add and remove some displays following their instructions to get familiar with the controls.\n",
    "\n",
    "## Basic setting\n",
    "\n",
    "We will guide you step by step to let you view the data recorded in the running rosbag.\n",
    "\n",
    "### Fixed Frame\n",
    "Fortunately, there is not much to configure to display data that we are interested in.\n",
    "After launching Rviz, we just have to tell it which coordinate frame we consider the _Fixed Frame_.\n",
    "This special coordinate frame is usually the not-moving one, for example a map frame, world frame, GPS frame - you name it.\n",
    "Rviz automatically transforms all coordinates in the displayed data into this frame and then draws them in the main 3D view.\n",
    "\n",
    "<img src=\"images/fixes_frame.png\" width=\"25%\" style=\"display:block; margin: 0 auto;\" />\n",
    "\n",
    "You will find the _Fixed Frame_ field in the _Global Options_ group in the _Displays_ panel, it is always the first one.\n",
    "Rviz lets you choose from coordinate frames present in the data.\n",
    "In our example bagfile, a good option for a Fixed Frame is the `odom` frame.\n",
    "\n",
    "### Grid\n",
    "\n",
    "Grid is just an optical guide in Rviz that helps us better understand the rendered 3D scene.\n",
    "It is a grid by default rendered in the origin of the Fixed Frame.\n",
    "You can set the number of cells and their size.\n",
    "With the grid displayed, you can finally see some effect of rotating the 3D view with mouse.\n",
    "Once we've mentioned using mouse, go to the [user guide](http://wiki.ros.org/rviz/UserGuide) page and see the section 6 to know which mouse button does what.\n",
    "\n",
    "<img src=\"images/grid.png\" width=\"25%\" style=\"display:block; margin: 0 auto;\" />\n",
    "\n",
    "### Target Frame\n",
    "\n",
    "Another useful setting is the _Target Frame_ in the _Views_ panel.\n",
    "To activate it, we need to go in the top menu and click `Panels -> Views`.\n",
    "It tells Rviz which coordinate frame to attach the view to.\n",
    "Setting of this parameter depends on what you want to focus on.\n",
    "If you were interested - for example - in observing a map which is static with respect to the fixed frame, the Target Frame would be the same as the _Fixed Frame_.\n",
    "If you wanted the view to move together with a robot which moves around the environment, you would attach the view to an approriate coordinate frame of the robot.\n",
    "In our case, such moving coordinate frame is called _base_link_.\n",
    "If you choose the robot as a target frame, you should see the grid moving - this is because the robot moved in the recorded bagfile and the view moves together with the robot.\n",
    "\n",
    "<img src=\"images/views.png\" width=\"25%\" style=\"display:block; margin: 0 auto;\" />\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Displaying real data\n",
    "\n",
    "Finally, we've got through the boring stuff and now we can focus on the interesting displays.\n",
    "You've guessed it, _coordinate frames_."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF\n",
    "\n",
    "ROS has a very useful system (_TF_) to keep track of transformations between coordinate frames.\n",
    "This allows you to track position of a robot in the fixed world frame as well.\n",
    "Or to look up position of an end-effector of a robotic arm with respect to the robot body.\n",
    "We will have a look at TF in more details in a [dedicated lesson](4-lesson-ros-tf.ipynb).\n",
    "For now, we will only focus on displaying them.\n",
    "\n",
    "Rviz has a display to visualize all these coordinate frames.\n",
    "It is called TF and generally needs no configuration - at the moment you add it, you should see all the frames.\n",
    "Or at least those for which there is a transformation into the fixed frame (so Rviz knows where to draw them).\n",
    "\n",
    "You should see something similar to this (yet more tiny) when you add the TF display:\n",
    "\n",
    "<img src=\"images/tf.png\" width=\"75%\" style=\"display:block; margin: 0 auto;\" />\n",
    "\n",
    "To take this screenshot, we have enlarged the markers by setting Scale to 20 and selected only a few Frames from the list.\n",
    "Try to achieve the same thing by exploring the menu &#9658; TF &#9658; Frames.\n",
    "\n",
    "Moreover, notice that the _odom_ frame lies in the center of the grid.\n",
    "Try changing the Fixed Frame to _map_ and see what the difference is.\n",
    "Also notice that the View type we use causes the camera to move with the Target Frame, but not to rotate.\n",
    "If you wanted the view to rotate with the robot, use the _ThirdPersonFollower_ view."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Point Clouds\n",
    "\n",
    "Ok, TF and coordinate frames are not such a thrill after all.\n",
    "Point clouds are the reason you chose this course, so here they come.\n",
    "The display for the type of point clouds we use is called _PointCloud2_.\n",
    "It needs to know the name of a ROS topic with the point cloud data.\n",
    "In our bagfile, the topic is called `/rslidar16_points`.\n",
    "Click the Add button to add a PointCloud2 and then select the appropriate topic.\n",
    "You should see something like this:\n",
    "\n",
    "<img src=\"images/pointcloud.png\" width=\"75%\" style=\"display:block; margin: 0 auto;\" />\n",
    "\n",
    "You can start by replicating the settings from the screenshot above to get similar results.\n",
    "Explore possibilities of this display type in the [documentation](http://wiki.ros.org/rviz/DisplayTypes/PointCloud).\n",
    "For example, try to change the coloring of the points from coloring by the Z axis coordinates into coloring by the intensity of received laser reflections.\n",
    "This is pretty much everything you need to know to display point clouds in Rviz.\n",
    "Easy, isn't it?"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Images\n",
    "\n",
    "Another display type we use all the time is the _Image_ display.\n",
    "It displays images, no surprise there.\n",
    "It needs to know the image topic name and the type of image transport used.\n",
    "ROS contains a mechanism which allows automatic image encoding and decoding called [_Image Transport_](http://wiki.ros.org/image_transport).\n",
    "It helps to save communication bandwidth by using jpeg, [Theora](https://en.wikipedia.org/wiki/Theora) or other compression algorithms.\n",
    "On a running robot, you would see among all topic a few maybe looking like this:\n",
    "- `/front_camera/camera_info`\n",
    "- `/front_camera/image`\n",
    "- `/front_camera/image/compressed`\n",
    "- `/front_camera/image/theora`\n",
    "\n",
    "The first topic `/front_camera/camera_info` contains camera calibration information useful for image analysis and re-projection.\n",
    "The following one, `/front_camera/image`, allows us to subscribe raw, uncompressed image data.\n",
    "The image messages will be HUGE.\n",
    "The Image Transport magic comes with the following topics, which transmit the same image, but in compressed form.\n",
    "_Compressed_ stands for JPEG compression, _theora_ for Theora codec which involves key frames and diff messages and which is intended for continuous video streaming (similarly to h.264) which also possible to run in Image Transport.\n",
    "\n",
    "The Rviz display needs to know the raw image topic name and the type of transport you wish the Rviz to use to get the images.\n",
    "In our bagfile, the images recorded by the Husky robot are stored in these topics:\n",
    "- `/camera_0/camera_info`\n",
    "- `/camera_0/image_raw/compressed`\n",
    "- `/camera_1/camera_info`\n",
    "- `/camera_1/image_raw/compressed`\n",
    "- `/camera_2/camera_info`\n",
    "- `/camera_2/image_raw/compressed`\n",
    "- `/camera_3/camera_info`\n",
    "- `/camera_3/image_raw/compressed`\n",
    "- `/camera_4/camera_info`\n",
    "- `/camera_4/image_raw/compressed`\n",
    "- `/camera_5/camera_info`\n",
    "- `/camera_5/image_raw/compressed`\n",
    "\n",
    "The `/camera_X/image_raw` raw-image messages were not recorded.\n",
    "If they were, the bagfile would be even bigger and now it is already around 560 MB for just a half a minute of recording...\n",
    "This does not prevent us from visualizing the images, it is just that Rviz is slightly confused and refuses to list available image topics in the drop-down menu in the Image display.\n",
    "You have to write it there manually, as the following screenshot suggests.\n",
    "The transport type we use is _compressed_, since it is the only one stored in the bagfile.\n",
    "\n",
    "\n",
    "<img src=\"images/image.png\" width=\"75%\" style=\"display:block; margin: 0 auto;\" />\n",
    "\n",
    "Explore the other image topics from the bagfile (camera_1 to camera_5) to look around the robot.\n",
    "Moreover, you can open the _Camera_ display instead of the _Image_ display.\n",
    "It has the same basic configuration fields, but the thing it draws is different...\n",
    "See for yourself.\n",
    "\n",
    "Once you are done, go to the [exercise](../../exercises/2-ex_ros/2.2-exercises_rviz.ipynb) for this lesson.\n",
    "\n",
    "Then, move on to the next lesson:\n",
    "- [Data recording and playback (rosbag)](2.3-lesson-ros-rosbag.ipynb)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "&#8635; [Go back to the list of lessons](2.0-overview.ipynb)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
